# config.yaml

# Use "./" for current directory, or any other path
output_dir: "generated_books"

generation_params:
  # Setting the name and gender of the author. They will be autogenerated if
  # not provided.
  author_name: "Fufu Fang"
  author_gender: "male"

  # Optional seed - used for generating a random topic if the main_topic is not
  # provided. If the main_topic and random_topic_seed are not supplied, a random
  # seed will be generated
  #random_topic_seed: "The quick brown fox jumps over the lazy dog"
  # random_topic_seed: ""

  # Setting the topic of the book. This will be autogenerated if not provided.
  # You can use a YAML multiline string here. 
  main_topic: >
      A philosophical discussion on the importance of moral high ground and physical high ground

  # Setting the title of the book. This will be autogenerated if not provided.
  # You can use a YAML multiline string here if needed.
  book_title: "The High Ground"

  # Setting the subtitle of the book. This will be autogenerated if not provided.
  # You can use a YAML multiline string here if needed.
  book_subtitle: "Moral and Physical"

  # When you are using gemma-3, you should add the word "extremely" here,
  # otherwise the book would be really long.
  #length_modifier: "extremely"

  # Is the generated book a fiction? Setting this true turns on character list
  # generation, disable chapter section generation.
  is_fiction: false

  # Whether to autogenerate a character list. This should only be turned on when
  # you are generating a novel.
  generate_character_list: false

  # Literary setting of the book. This will be autogenerated if not specified
  # You can use a YAML multiline string here.
  setting: >
    Contemporary real world

  # Setting the tone of the writing. This will be autogenerated if not 
  # specified.
  # writing_tone: "academic, scholarly, authoritive, non-fiction"

  # A list of key concepts covered by the book. This will be autogenerated if
  # not specified.
  # key_concepts:
  #   - "Mathematical formulae"
  #   - "Integration"
  #   - "Differentiation"
  #   - "Trignometry"

  # These are not really used unless there are some sort of problems.
  # Fall back chapter count
  num_chapter_fallback: 3
  # Fall back section count
  num_sections_per_chapter_fallback: 2

# API Provider and Global Settings
# This section groups all API related configurations.
api_settings:
  provider: "gemini"  # Can be "gemini" or "ollama" (Update as per your previous change)

  # Default settings applicable to API calls, can be overridden by provider-specific sections.
  default_max_retries: 10
  default_retry_delay_seconds: 30
  base_cache_dir: "api_cache"     # Base directory for API call caching

  # Gemini specific settings
  gemini:
    # The LLM model to be used
    # Different models have different rate limits, for more, please visit:
    # https://ai.google.dev/gemini-api/docs/rate-limits#current-rate-limits
    # At the time of writing, Gemma 3 has a Request-Per-Day (RPD) of 14,400,
    # whereas Gemini 2.5 Flash Preview has a RPD of 500. It is therefore recommended
    # to use Gemma 3 for testing purposes.
    # model: "gemma-3-27b-it"
    model: "gemini-2.5-flash-preview-04-17"
    # temperature controls the randomness or "creativity" of the model.
    temperature: 0.7
    # To use Gemini-specific retries different from default, uncomment and set:
    max_retries: 10
    retry_delay_seconds: 60

  # Ollama specific settings (assuming this structure from previous integration)
  ollama:
    base_url: "http://localhost:11434" # Your Ollama server address
    model: "gemma3:12b"                    # The Ollama model you want to use
    tokenizer_model: "google/gemma-3-1b-it" # Tokenizer for client-side counting
    temperature: 0.7
    # To use Ollama-specific retries different from default:
    max_retries: 3
    retry_delay_seconds: 5
    request_timeout_seconds: 180       # Timeout for Ollama requests (e.g., 3 minutes)

# The following keys are assumed to be moved if they existed at the top level
# api_provider: "gemini" # MOVED into api_settings
# ollama_settings: ...   # MOVED into api_settings.ollama

style_params:
  font_name: "Cambria"
  font_size: 10.5

  page_size_preset: "6x9" # Currently only "6x9" is explicitly supported for margins
  margins_mm:
      top: 10
      bottom: 10
      right: 10
      left: 4
      gutter: 16

  # Multiplier for inline math height based on font size
  inline_math_height_multiplier: 1.05
  # Height in inches for display math images
  display_math_height_inches: 0.5
  # Vertical offset for inline math images in half-points.
  # Negative values shift down, positive values shift up.
  # Example: -4 means shift down by 2 points. 0 means no shift.
  # Default is -4 if not specified.
  inline_math_vertical_offset_half_points: -5

debug_options:
  verbose_debug: true
  save_intermediate_html: true
